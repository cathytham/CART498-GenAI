{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CHzBraxMpT9",
        "outputId": "99f1d8b3-dd9c-4e38-992e-0e106a967757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Original Poem ===\n",
            "One must have a mind of winter\n",
            "To regard the frost and the boughs\n",
            "Of the pine-trees crusted with snow;\n",
            "And have been cold a long time\n",
            "To behold the junipers shagged with ice,\n",
            "The spruces rough in the distant glitter\n",
            "Of the January sun; and not to think\n",
            "Of any misery in the sound of the wind,\n",
            "In the sound of a few leaves,\n",
            "Which is the sound of the land\n",
            "Full of the same wind\n",
            "That is blowing in the same bare place\n",
            "For the listener, who listens in the snow,\n",
            "And, nothing himself, beholds\n",
            "Nothing that is not there and the nothing that is.\n",
            "\n",
            "=== Modified Poem (P+7) ===\n",
            "One must have a mind of or\n",
            "To regard the frost and the which\n",
            "Of the pine-trees crusted with but;\n",
            "And have been cold a long so\n",
            "To behold the junipers shagged with he,\n",
            "The spruces rough in the distant in\n",
            "Of the January sun; and not to about\n",
            "Of any misery in the sound of the let,\n",
            "In the sound of a few and,\n",
            "Which is the sound of the on\n",
            "Full of the same from\n",
            "That is blowing in the same bare I\n",
            "For the listener, who listens in the this,\n",
            "And, nothing himself, what\n",
            "Nothing that is not there and the nothing that You.\n",
            "\n",
            "=== Modified Poem (P+35) ===\n",
            "One must have a mind of ish\n",
            "To regard the frost and the there\n",
            "Of the pine-trees crusted with so;\n",
            "And have been cold a long that\n",
            "To behold the junipers shagged with while,\n",
            "The spruces rough in the distant under\n",
            "Of the January sun; and not to then\n",
            "Of any misery in the sound of the of,\n",
            "In the sound of a few A,\n",
            "Which is the sound of the I\n",
            "Full of the same speeds\n",
            "That is blowing in the same bare across\n",
            "For the listener, who listens in the watch,\n",
            "And, nothing himself, God\n",
            "Nothing that is not there and the nothing that Not.\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Function to extract the Nth most likely word while filtering out punctuation\n",
        "def fetch_nth_token(model, tokenizer, prompt, n):\n",
        "    # Tokenize input\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Get model predictions\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids)\n",
        "        # Last word prediction\n",
        "        logits = output.logits[0, -1]\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Filter out punctuation tokens\n",
        "    token_ids = torch.arange(probs.size(0))\n",
        "    non_punct_tokens = [tid.item() for tid in token_ids if tokenizer.decode([tid]).strip().isalpha()]\n",
        "\n",
        "    if not non_punct_tokens:\n",
        "        # Fallback if no valid tokens exist\n",
        "        return None\n",
        "\n",
        "    filtered_indices = torch.tensor(non_punct_tokens, device=probs.device)\n",
        "    filtered_probs = probs[filtered_indices]\n",
        "\n",
        "    # Fetch the nth most probable word, or fallback\n",
        "    if len(filtered_probs) >= n:\n",
        "        nth_token_id = filtered_indices[torch.topk(filtered_probs, k=n).indices[-1]].item()\n",
        "    else:\n",
        "        nth_token_id = filtered_indices[-1].item()\n",
        "\n",
        "    return tokenizer.decode([nth_token_id]).strip()\n",
        "\n",
        "# Function to preserve punctuation while replacing only the last word\n",
        "def replace_last_word(line, new_word):\n",
        "    words = line.split()\n",
        "    if not words:\n",
        "        # Return empty lines unchanged\n",
        "        return line\n",
        "\n",
        "    last_word = words[-1]\n",
        "\n",
        "    # Check if the last word has punctuation\n",
        "    stripped_word = last_word.rstrip(string.punctuation)\n",
        "    # Get the punctuation\n",
        "    trailing_punct = last_word[len(stripped_word):]\n",
        "\n",
        "    # Replace last word while keeping punctuation\n",
        "    return \" \".join(words[:-1] + [new_word + trailing_punct])\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Original poem - The Snow Man by Wallace Stevens (1879-1955)\n",
        "poem_lines = [\n",
        "    \"One must have a mind of winter\",\n",
        "    \"To regard the frost and the boughs\",\n",
        "    \"Of the pine-trees crusted with snow;\",\n",
        "    \"And have been cold a long time\",\n",
        "    \"To behold the junipers shagged with ice,\",\n",
        "    \"The spruces rough in the distant glitter\",\n",
        "    \"Of the January sun; and not to think\",\n",
        "    \"Of any misery in the sound of the wind,\",\n",
        "    \"In the sound of a few leaves,\",\n",
        "    \"Which is the sound of the land\",\n",
        "    \"Full of the same wind\",\n",
        "    \"That is blowing in the same bare place\",\n",
        "    \"For the listener, who listens in the snow,\",\n",
        "    \"And, nothing himself, beholds\",\n",
        "    \"Nothing that is not there and the nothing that is.\"\n",
        "]\n",
        "\n",
        "# Print the original poem\n",
        "print(\"\\n=== Original Poem ===\")\n",
        "for line in poem_lines:\n",
        "    print(line)\n",
        "\n",
        "# Apply P+7 transformation\n",
        "modified_poem_p7 = []\n",
        "modified_poem_px = []\n",
        "\n",
        "for line in poem_lines:\n",
        "    words = line.split()\n",
        "    if not words:\n",
        "        modified_poem_p7.append(line)\n",
        "        modified_poem_px.append(line)\n",
        "        continue\n",
        "\n",
        "    last_word = words[-1].rstrip(string.punctuation)\n",
        "\n",
        "    new_word_p7 = fetch_nth_token(gpt2, tokenizer, \" \".join(words), 7) or last_word\n",
        "    new_word_px = fetch_nth_token(gpt2, tokenizer, \" \".join(words), 35) or last_word\n",
        "\n",
        "    modified_poem_p7.append(replace_last_word(line, new_word_p7))\n",
        "    modified_poem_px.append(replace_last_word(line, new_word_px))\n",
        "\n",
        "# Print the modified poem (P+7)\n",
        "print(\"\\n=== Modified Poem (P+7) ===\")\n",
        "for line in modified_poem_p7:\n",
        "    print(line)\n",
        "\n",
        "# Print the modified poem (P+35)\n",
        "print(\"\\n=== Modified Poem (P+35) ===\")\n",
        "for line in modified_poem_px:\n",
        "    print(line)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
